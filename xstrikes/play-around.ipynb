{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.expanduser('~'), 'git_repos', 'TK5', 'Data', 'nwds-xstrikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'sample_solution.csv', 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "df_sample = pd.read_csv(os.path.join(data_dir, 'sample_solution.csv'))\n",
    "df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_lefty'] = 0\n",
    "df_train.loc[df_train['p_throws'] == 'L', 'is_lefty'] = 1\n",
    "df_test['is_lefty'] = 0\n",
    "df_test.loc[df_test['p_throws'] == 'L', 'is_lefty'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sz_top</th>\n",
       "      <th>sz_bot</th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>release_pos_x</th>\n",
       "      <th>release_pos_y</th>\n",
       "      <th>release_pos_z</th>\n",
       "      <th>stand</th>\n",
       "      <th>p_throws</th>\n",
       "      <th>inning</th>\n",
       "      <th>inning_topbot</th>\n",
       "      <th>outs_when_up</th>\n",
       "      <th>balls</th>\n",
       "      <th>strikes</th>\n",
       "      <th>if_fielding_alignment</th>\n",
       "      <th>of_fielding_alignment</th>\n",
       "      <th>on_3b</th>\n",
       "      <th>on_2b</th>\n",
       "      <th>on_1b</th>\n",
       "      <th>release_speed</th>\n",
       "      <th>spin_axis</th>\n",
       "      <th>release_spin_rate</th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>plate_x</th>\n",
       "      <th>plate_z</th>\n",
       "      <th>is_lefty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122428</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.55</td>\n",
       "      <td>SI</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>54.31</td>\n",
       "      <td>6.59</td>\n",
       "      <td>L</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>Top</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Infield shift</td>\n",
       "      <td>Standard</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>93.8</td>\n",
       "      <td>202</td>\n",
       "      <td>2333</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291855</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.56</td>\n",
       "      <td>FC</td>\n",
       "      <td>2.68</td>\n",
       "      <td>53.84</td>\n",
       "      <td>5.67</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>Top</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Strategic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>88.5</td>\n",
       "      <td>153</td>\n",
       "      <td>2068</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225539</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.69</td>\n",
       "      <td>CH</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>54.73</td>\n",
       "      <td>6.94</td>\n",
       "      <td>L</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Strategic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>78.5</td>\n",
       "      <td>221</td>\n",
       "      <td>1609</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1410</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1.71</td>\n",
       "      <td>FF</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>54.33</td>\n",
       "      <td>5.98</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>6</td>\n",
       "      <td>Top</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>94.0</td>\n",
       "      <td>220</td>\n",
       "      <td>2265</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256048</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.42</td>\n",
       "      <td>FF</td>\n",
       "      <td>3.77</td>\n",
       "      <td>53.53</td>\n",
       "      <td>3.40</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>7</td>\n",
       "      <td>Bot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Standard</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>90.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2158</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  sz_top  sz_bot pitch_type  release_pos_x  release_pos_y  \\\n",
       "0  122428    3.06    1.55         SI          -1.90          54.31   \n",
       "1  291855    3.29    1.56         FC           2.68          53.84   \n",
       "2  225539    3.62    1.69         CH          -1.17          54.73   \n",
       "3    1410    3.42    1.71         FF          -1.41          54.33   \n",
       "4  256048    3.14    1.42         FF           3.77          53.53   \n",
       "\n",
       "   release_pos_z stand p_throws  inning inning_topbot  outs_when_up  balls  \\\n",
       "0           6.59     L        R       1           Top             2      1   \n",
       "1           5.67     R        L       4           Top             0      0   \n",
       "2           6.94     L        R       4           Bot             0      1   \n",
       "3           5.98     R        R       6           Top             2      0   \n",
       "4           3.40     R        L       7           Bot             0      0   \n",
       "\n",
       "   strikes if_fielding_alignment of_fielding_alignment  on_3b  on_2b  on_1b  \\\n",
       "0        1         Infield shift              Standard  False  False  False   \n",
       "1        1              Standard             Strategic  False  False  False   \n",
       "2        0              Standard             Strategic  False  False  False   \n",
       "3        0              Standard              Standard  False  False  False   \n",
       "4        2              Standard              Standard  False  False   True   \n",
       "\n",
       "   release_speed  spin_axis  release_spin_rate  pfx_x  pfx_z  plate_x  \\\n",
       "0           93.8        202               2333  -1.10   1.05     0.99   \n",
       "1           88.5        153               2068  -0.14   0.80     0.16   \n",
       "2           78.5        221               1609  -0.73   0.62    -0.05   \n",
       "3           94.0        220               2265  -0.69   1.33     1.30   \n",
       "4           90.8        100               2158   1.56   0.60    -0.18   \n",
       "\n",
       "   plate_z  is_lefty  \n",
       "0     2.19         0  \n",
       "1     3.06         1  \n",
       "2     2.45         0  \n",
       "3     2.24         0  \n",
       "4     3.76         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'sz_top', 'sz_bot', 'pitch_type', 'release_pos_x',\n",
       "       'release_pos_y', 'release_pos_z', 'stand', 'p_throws', 'inning',\n",
       "       'inning_topbot', 'outs_when_up', 'balls', 'strikes',\n",
       "       'if_fielding_alignment', 'of_fielding_alignment', 'on_3b', 'on_2b',\n",
       "       'on_1b', 'release_speed', 'spin_axis', 'release_spin_rate', 'pfx_x',\n",
       "       'pfx_z', 'plate_x', 'plate_z', 'is_strike', 'is_lefty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_feats = ['uid', 'pitch_type']\n",
    "feats = ['release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'release_pos_x',\n",
    "       'release_pos_y', 'release_pos_z', 'balls', 'strikes', 'plate_x', 'plate_z', 'is_lefty']\n",
    "target = \"is_strike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kf.split(df_train):\n",
    "    train = df_train.iloc[train_index].copy()\n",
    "    val = df_train.iloc[val_index].copy()\n",
    "    \n",
    "    xgb = XGBClassifier(n_estimators=1000, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "    xgb.fit(train[feats], train[target])\n",
    "    \n",
    "    dfs_pred = {}\n",
    "    y_pred = xgb.predict_proba(val[feats])\n",
    "    dfs_pred[target] = pd.Series(y_pred[:, 1], index=val.index)\n",
    "    dfs_pred['uid'] = val['uid']\n",
    "    df_pred = pd.concat(dfs_pred, axis=1)\n",
    "    df_xgb = pd.concat([df_xgb, df_pred], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_strike</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281567</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.379605</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.177834</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.371208</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.300899</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.312730</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.318394</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.346544</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.310577</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.190925</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.346009</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.399574</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.371299</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.201860</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.266725</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.321458</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.399597</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.406626</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.335736</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_strike  uid\n",
       "0    0.386028    0\n",
       "6    0.281567    6\n",
       "11   0.379605   11\n",
       "12   0.177834   13\n",
       "16   0.371208   17\n",
       "22   0.300899   23\n",
       "24   0.312730   25\n",
       "26   0.318394   27\n",
       "30   0.346544   31\n",
       "33   0.310577   34\n",
       "35   0.190925   36\n",
       "41   0.346009   42\n",
       "44   0.399574   45\n",
       "49   0.371299   50\n",
       "53   0.201860   54\n",
       "79   0.266725   82\n",
       "80   0.321458   83\n",
       "87   0.399597   91\n",
       "88   0.406626   92\n",
       "89   0.335736   93"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_strike_xgb'] = df_xgb['is_strike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>is_strike</th>\n",
       "      <th>is_strike_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.359420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.331893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.288775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.359913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  is_strike  is_strike_xgb\n",
       "0     0          1       0.386028\n",
       "1     1          1       0.364724\n",
       "2     2          1       0.347803\n",
       "3     3          1       0.359420\n",
       "4     4          0       0.331893\n",
       "5     5          1       0.288775\n",
       "6     6          0       0.281567\n",
       "7     7          1       0.305260\n",
       "8     8          1       0.281813\n",
       "9     9          1       0.307256\n",
       "10   10          1       0.402424\n",
       "11   11          1       0.379605\n",
       "12   13          0       0.177834\n",
       "13   14          0       0.335354\n",
       "14   15          0       0.399953\n",
       "15   16          0       0.300642\n",
       "16   17          1       0.371208\n",
       "17   18          0       0.368108\n",
       "18   19          0       0.364660\n",
       "19   20          0       0.359913"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['uid', 'is_strike', 'is_strike_xgb']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629669937669223"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(df_train['is_strike'], df_train['is_strike_xgb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(df_train[feats], df_train[target])\n",
    "\n",
    "dfs_pred = {}\n",
    "y_pred = xgb.predict_proba(df_test[feats])\n",
    "dfs_pred[target] = pd.Series(y_pred[:, 1], index=df_test.index)\n",
    "dfs_pred['uid'] = df_test['uid']\n",
    "df_pred = pd.concat(dfs_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[['uid', 'is_strike']].to_csv('preds/pred_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df_train[feats], df_train[target], test_size=0.2, random_state=42)\n",
    "\n",
    "    params = {\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "        }\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(train_x, train_y, verbose=False)\n",
    "\n",
    "    preds = model.predict(test_x)\n",
    "    loss = log_loss(test_y, preds)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-04 17:06:16,540]\u001b[0m A new study created in memory with name: no-name-10f6609e-37dd-451d-943a-0fe84d5b864d\u001b[0m\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2465: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2465: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "\u001b[33m[W 2023-03-04 17:06:22,804]\u001b[0m Trial 0 failed with parameters: {'lambda': 3.8995304475556787, 'alpha': 2.643963943231714, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.1, 'min_child_weight': 192} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-03-04 17:06:22,805]\u001b[0m Trial 0 failed with value nan.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:06:27,750]\u001b[0m Trial 1 finished with value: 0.5215944081419538 and parameters: {'lambda': 1.6182442814090163, 'alpha': 7.433857773790648, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.01, 'min_child_weight': 179}. Best is trial 1 with value: 0.5215944081419538.\u001b[0m\n",
      "\u001b[33m[W 2023-03-04 17:06:30,493]\u001b[0m Trial 2 failed with parameters: {'lambda': 1.9308103388575615, 'alpha': 5.351959469423343, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.02, 'min_child_weight': 80} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/ts/3wmv3bq14n37zqx8km69cxtm0000gn/T/ipykernel_15099/158949646.py\", line 15, in tune\n",
      "    model.fit(train_x, train_y, verbose=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-03-04 17:06:30,495]\u001b[0m Trial 2 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(tune, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of finished trials:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [101], line 15\u001b[0m, in \u001b[0;36mtune\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlambda\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlambda\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-3\u001b[39m, \u001b[39m10.0\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1e-3\u001b[39m, \u001b[39m10.0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m300\u001b[39m),\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     14\u001b[0m model \u001b[39m=\u001b[39m XGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 15\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_x, train_y, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     17\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_x)\n\u001b[1;32m     18\u001b[0m loss \u001b[39m=\u001b[39m log_loss(test_y, preds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(tune, n_trials=100)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_trial.params\n",
    "\n",
    "model = XGBRegressor(**params)\n",
    "model.fit(df_train[feats], df_train[target], verbose=False)\n",
    "\n",
    "preds = model.predict(df_test[feats])\n",
    "dfs_pred = {}\n",
    "dfs_pred['uid'] = df_test['uid']\n",
    "dfs_pred[target] = pd.Series(preds, index=df_test.index)\n",
    "df_pred = pd.concat(dfs_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[['uid', 'is_strike']].to_csv('preds/pred_xgb_optuna.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost go Brrrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_catboost(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df_train[feats], df_train[target], test_size=0.2, random_state=42)\n",
    "\n",
    "    params = {\n",
    "        \"iterations\" : trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-3, 1.0),\n",
    "        \"random_seed\" : 42,\n",
    "        'logging_level': 'Silent',\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(train_x, train_y, verbose=False)\n",
    "\n",
    "    preds = model.predict(test_x)\n",
    "    loss = log_loss(test_y, preds)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-04 17:23:56,286]\u001b[0m A new study created in memory with name: no-name-a4ee9c39-fa43-4308-823b-40375f6a175b\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:14,914]\u001b[0m Trial 0 finished with value: 0.24186796341868794 and parameters: {'iterations': 972, 'learning_rate': 0.7388031219020379}. Best is trial 0 with value: 0.24186796341868794.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:21,348]\u001b[0m Trial 1 finished with value: 0.1789001466517139 and parameters: {'iterations': 313, 'learning_rate': 0.3391204100579025}. Best is trial 1 with value: 0.1789001466517139.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:35,073]\u001b[0m Trial 2 finished with value: 0.18664743156901764 and parameters: {'iterations': 972, 'learning_rate': 0.2431452716258222}. Best is trial 1 with value: 0.1789001466517139.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:39,586]\u001b[0m Trial 3 finished with value: 0.22799931096859952 and parameters: {'iterations': 301, 'learning_rate': 0.8995287618555415}. Best is trial 1 with value: 0.1789001466517139.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:43,888]\u001b[0m Trial 4 finished with value: 0.19087052468088564 and parameters: {'iterations': 303, 'learning_rate': 0.008735615994625648}. Best is trial 1 with value: 0.1789001466517139.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:48,833]\u001b[0m Trial 5 finished with value: 0.17609883916323302 and parameters: {'iterations': 355, 'learning_rate': 0.28237827701697604}. Best is trial 5 with value: 0.17609883916323302.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:24:59,926]\u001b[0m Trial 6 finished with value: 0.25895712787666636 and parameters: {'iterations': 779, 'learning_rate': 0.9609926845353158}. Best is trial 5 with value: 0.17609883916323302.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:08,907]\u001b[0m Trial 7 finished with value: 0.17871507071915166 and parameters: {'iterations': 660, 'learning_rate': 0.2681220053636609}. Best is trial 5 with value: 0.17609883916323302.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:18,720]\u001b[0m Trial 8 finished with value: 0.16768633717952056 and parameters: {'iterations': 712, 'learning_rate': 0.052617837109788276}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:30,412]\u001b[0m Trial 9 finished with value: 0.17722236753484913 and parameters: {'iterations': 867, 'learning_rate': 0.19599578866476172}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:37,439]\u001b[0m Trial 10 finished with value: 0.20378696170843552 and parameters: {'iterations': 516, 'learning_rate': 0.5525745621809239}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:38,929]\u001b[0m Trial 11 finished with value: 0.2201578740180317 and parameters: {'iterations': 101, 'learning_rate': 0.01877953846382599}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:46,672]\u001b[0m Trial 12 finished with value: 0.19120565721074642 and parameters: {'iterations': 520, 'learning_rate': 0.42672773802854824}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:25:57,305]\u001b[0m Trial 13 finished with value: 0.17359554476313038 and parameters: {'iterations': 653, 'learning_rate': 0.15516296321373768}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:07,822]\u001b[0m Trial 14 finished with value: 0.16943839883475006 and parameters: {'iterations': 708, 'learning_rate': 0.08177096815907471}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:18,567]\u001b[0m Trial 15 finished with value: 0.1697858515048631 and parameters: {'iterations': 721, 'learning_rate': 0.06879823570970883}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:29,667]\u001b[0m Trial 16 finished with value: 0.1694800904044859 and parameters: {'iterations': 843, 'learning_rate': 0.11115813216512418}. Best is trial 8 with value: 0.16768633717952056.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:36,754]\u001b[0m Trial 17 finished with value: 0.16692463922420406 and parameters: {'iterations': 596, 'learning_rate': 0.12161773463738282}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:43,766]\u001b[0m Trial 18 finished with value: 0.17535099977276974 and parameters: {'iterations': 585, 'learning_rate': 0.15706484213306546}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:49,964]\u001b[0m Trial 19 finished with value: 0.25076678569015654 and parameters: {'iterations': 429, 'learning_rate': 0.003433608205538896}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:26:57,061]\u001b[0m Trial 20 finished with value: 0.18932097315169324 and parameters: {'iterations': 588, 'learning_rate': 0.374134830390667}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:06,212]\u001b[0m Trial 21 finished with value: 0.17342444631191242 and parameters: {'iterations': 717, 'learning_rate': 0.14001934898241253}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:15,903]\u001b[0m Trial 22 finished with value: 0.16901964509684747 and parameters: {'iterations': 819, 'learning_rate': 0.09503668943159184}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:25,617]\u001b[0m Trial 23 finished with value: 0.1883851547183923 and parameters: {'iterations': 843, 'learning_rate': 0.23596007745295328}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:34,950]\u001b[0m Trial 24 finished with value: 0.17059021841389208 and parameters: {'iterations': 786, 'learning_rate': 0.09054479213413598}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:45,948]\u001b[0m Trial 25 finished with value: 0.18284291445951245 and parameters: {'iterations': 903, 'learning_rate': 0.191753531911577}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:51,632]\u001b[0m Trial 26 finished with value: 0.16825337424297748 and parameters: {'iterations': 452, 'learning_rate': 0.08570599776833343}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:27:59,359]\u001b[0m Trial 27 finished with value: 0.2844686843300785 and parameters: {'iterations': 444, 'learning_rate': 0.0025897272107659186}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:07,749]\u001b[0m Trial 28 finished with value: 0.17236816175157288 and parameters: {'iterations': 456, 'learning_rate': 0.17314952686423696}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:10,304]\u001b[0m Trial 29 finished with value: 0.1853925482012983 and parameters: {'iterations': 144, 'learning_rate': 0.5426210454583095}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:20,524]\u001b[0m Trial 30 finished with value: 0.18782044066776402 and parameters: {'iterations': 633, 'learning_rate': 0.29813588222394627}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:35,110]\u001b[0m Trial 31 finished with value: 0.1683939484694045 and parameters: {'iterations': 778, 'learning_rate': 0.07985342634080454}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:44,805]\u001b[0m Trial 32 finished with value: 0.167756442278041 and parameters: {'iterations': 564, 'learning_rate': 0.08592607182848931}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:53,503]\u001b[0m Trial 33 finished with value: 0.17329153882130857 and parameters: {'iterations': 551, 'learning_rate': 0.1909184350653168}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:28:59,468]\u001b[0m Trial 34 finished with value: 0.17275121311858857 and parameters: {'iterations': 389, 'learning_rate': 0.2258969012632901}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:06,704]\u001b[0m Trial 35 finished with value: 0.16860751134677396 and parameters: {'iterations': 501, 'learning_rate': 0.04738695312044408}. Best is trial 17 with value: 0.16692463922420406.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:09,971]\u001b[0m Trial 36 finished with value: 0.16464768049360612 and parameters: {'iterations': 224, 'learning_rate': 0.12438859122831876}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:12,755]\u001b[0m Trial 37 finished with value: 0.16983475025105252 and parameters: {'iterations': 186, 'learning_rate': 0.14860094460790496}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:16,609]\u001b[0m Trial 38 finished with value: 0.17573696030638622 and parameters: {'iterations': 263, 'learning_rate': 0.31928501542062576}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:20,217]\u001b[0m Trial 39 finished with value: 0.17196209657051442 and parameters: {'iterations': 240, 'learning_rate': 0.23377627551677538}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:29,165]\u001b[0m Trial 40 finished with value: 0.16530139790508974 and parameters: {'iterations': 593, 'learning_rate': 0.048956242639676184}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:38,020]\u001b[0m Trial 41 finished with value: 0.16651611968028707 and parameters: {'iterations': 617, 'learning_rate': 0.04534961752161057}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:47,344]\u001b[0m Trial 42 finished with value: 0.16642429395229344 and parameters: {'iterations': 636, 'learning_rate': 0.03960386822442065}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:29:56,971]\u001b[0m Trial 43 finished with value: 0.16556360787620075 and parameters: {'iterations': 620, 'learning_rate': 0.04004126971483485}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:06,538]\u001b[0m Trial 44 finished with value: 0.16597182206865352 and parameters: {'iterations': 667, 'learning_rate': 0.039249688848736745}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:16,490]\u001b[0m Trial 45 finished with value: 0.16707212982454672 and parameters: {'iterations': 675, 'learning_rate': 0.0491428412849267}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:21,676]\u001b[0m Trial 46 finished with value: 0.29982263890654975 and parameters: {'iterations': 349, 'learning_rate': 0.00296213926499847}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:32,724]\u001b[0m Trial 47 finished with value: 0.17034965445168337 and parameters: {'iterations': 681, 'learning_rate': 0.1289920186525514}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:40,113]\u001b[0m Trial 48 finished with value: 0.16838322540938955 and parameters: {'iterations': 496, 'learning_rate': 0.04264445622435917}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:30:51,100]\u001b[0m Trial 49 finished with value: 0.18063553669135787 and parameters: {'iterations': 764, 'learning_rate': 0.2711418976280582}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:02,650]\u001b[0m Trial 50 finished with value: 0.17301475778070025 and parameters: {'iterations': 746, 'learning_rate': 0.12706853555129316}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:11,902]\u001b[0m Trial 51 finished with value: 0.16679276622557865 and parameters: {'iterations': 630, 'learning_rate': 0.0447625398919195}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:21,037]\u001b[0m Trial 52 finished with value: 0.16635284085810562 and parameters: {'iterations': 628, 'learning_rate': 0.043374063057102716}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:29,198]\u001b[0m Trial 53 finished with value: 0.16752298755325953 and parameters: {'iterations': 531, 'learning_rate': 0.02912713469568147}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:39,157]\u001b[0m Trial 54 finished with value: 0.1698440612695903 and parameters: {'iterations': 695, 'learning_rate': 0.12635890495786833}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:48,284]\u001b[0m Trial 55 finished with value: 0.17318347542177664 and parameters: {'iterations': 653, 'learning_rate': 0.17206186377721408}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:31:57,571]\u001b[0m Trial 56 finished with value: 0.23428264305797286 and parameters: {'iterations': 610, 'learning_rate': 0.002763221315852396}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:05,711]\u001b[0m Trial 57 finished with value: 0.16756103772077371 and parameters: {'iterations': 547, 'learning_rate': 0.0680808618806441}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:13,838]\u001b[0m Trial 58 finished with value: 0.16624741518556607 and parameters: {'iterations': 573, 'learning_rate': 0.10149049471542038}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:22,006]\u001b[0m Trial 59 finished with value: 0.16658861872180683 and parameters: {'iterations': 578, 'learning_rate': 0.11069648887141897}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:29,724]\u001b[0m Trial 60 finished with value: 0.17507240140879965 and parameters: {'iterations': 492, 'learning_rate': 0.19220289268276725}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:40,871]\u001b[0m Trial 61 finished with value: 0.1683628298320006 and parameters: {'iterations': 642, 'learning_rate': 0.10883633808447483}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:32:53,527]\u001b[0m Trial 62 finished with value: 0.1680648422184876 and parameters: {'iterations': 741, 'learning_rate': 0.02789937261092716}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:02,708]\u001b[0m Trial 63 finished with value: 0.1647493782570652 and parameters: {'iterations': 601, 'learning_rate': 0.07181469159345308}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:11,773]\u001b[0m Trial 64 finished with value: 0.16716115730918826 and parameters: {'iterations': 600, 'learning_rate': 0.07189480847855047}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:19,095]\u001b[0m Trial 65 finished with value: 0.17166066330201768 and parameters: {'iterations': 478, 'learning_rate': 0.15569559343918415}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:25,413]\u001b[0m Trial 66 finished with value: 0.16975590338602278 and parameters: {'iterations': 411, 'learning_rate': 0.10687468197354005}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:39,174]\u001b[0m Trial 67 finished with value: 0.16931321631651294 and parameters: {'iterations': 975, 'learning_rate': 0.06957130537544647}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:47,342]\u001b[0m Trial 68 finished with value: 0.16806826608367656 and parameters: {'iterations': 533, 'learning_rate': 0.1356294668346007}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:33:57,877]\u001b[0m Trial 69 finished with value: 0.18206204085451733 and parameters: {'iterations': 665, 'learning_rate': 0.2218462269250479}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:06,136]\u001b[0m Trial 70 finished with value: 0.16782635748214297 and parameters: {'iterations': 576, 'learning_rate': 0.027379234196090788}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:16,275]\u001b[0m Trial 71 finished with value: 0.16959038321672049 and parameters: {'iterations': 703, 'learning_rate': 0.0954537636953094}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:25,833]\u001b[0m Trial 72 finished with value: 0.16770716938227176 and parameters: {'iterations': 623, 'learning_rate': 0.06021429937701944}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:33,934]\u001b[0m Trial 73 finished with value: 0.1675726445739685 and parameters: {'iterations': 558, 'learning_rate': 0.026637397420770644}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:42,996]\u001b[0m Trial 74 finished with value: 0.16850543708841897 and parameters: {'iterations': 597, 'learning_rate': 0.08206570890324413}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:34:52,950]\u001b[0m Trial 75 finished with value: 0.2232091392309987 and parameters: {'iterations': 655, 'learning_rate': 0.002837728983607228}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:03,290]\u001b[0m Trial 76 finished with value: 0.17216997614988752 and parameters: {'iterations': 688, 'learning_rate': 0.15982185112442435}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:10,556]\u001b[0m Trial 77 finished with value: 0.16569568443468097 and parameters: {'iterations': 514, 'learning_rate': 0.05659251774614262}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:18,374]\u001b[0m Trial 78 finished with value: 0.16854093209093493 and parameters: {'iterations': 528, 'learning_rate': 0.1035966375983931}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:23,318]\u001b[0m Trial 79 finished with value: 0.1687952625896411 and parameters: {'iterations': 326, 'learning_rate': 0.07317609484379271}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:35,128]\u001b[0m Trial 80 finished with value: 0.17414562736870492 and parameters: {'iterations': 817, 'learning_rate': 0.13874815779956332}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:44,137]\u001b[0m Trial 81 finished with value: 0.16689010187108064 and parameters: {'iterations': 630, 'learning_rate': 0.04920287612085949}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:35:57,636]\u001b[0m Trial 82 finished with value: 0.16843581107488356 and parameters: {'iterations': 919, 'learning_rate': 0.022033499755984322}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:08,283]\u001b[0m Trial 83 finished with value: 0.1681111275611437 and parameters: {'iterations': 730, 'learning_rate': 0.055798333156148}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:10,173]\u001b[0m Trial 84 finished with value: 0.1698912519500077 and parameters: {'iterations': 124, 'learning_rate': 0.08989144288834394}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:18,457]\u001b[0m Trial 85 finished with value: 0.16768043606646746 and parameters: {'iterations': 588, 'learning_rate': 0.03170764943258268}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:26,535]\u001b[0m Trial 86 finished with value: 0.16851779145689935 and parameters: {'iterations': 567, 'learning_rate': 0.12436504906836676}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:29,937]\u001b[0m Trial 87 finished with value: 0.5032915271515284 and parameters: {'iterations': 229, 'learning_rate': 0.0010393341797507658}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:40,404]\u001b[0m Trial 88 finished with value: 0.16772865753495636 and parameters: {'iterations': 661, 'learning_rate': 0.057546252065314614}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:47,746]\u001b[0m Trial 89 finished with value: 0.17272317885370994 and parameters: {'iterations': 511, 'learning_rate': 0.16828403822999427}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:36:51,941]\u001b[0m Trial 90 finished with value: 0.1702472463149342 and parameters: {'iterations': 286, 'learning_rate': 0.11571323038064836}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:01,476]\u001b[0m Trial 91 finished with value: 0.1667860820046434 and parameters: {'iterations': 619, 'learning_rate': 0.03926209924723666}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:10,517]\u001b[0m Trial 92 finished with value: 0.16888589945118487 and parameters: {'iterations': 613, 'learning_rate': 0.08975855611586653}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:19,909]\u001b[0m Trial 93 finished with value: 0.16611400699676354 and parameters: {'iterations': 647, 'learning_rate': 0.060858070352265065}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:30,243]\u001b[0m Trial 94 finished with value: 0.16668081882806451 and parameters: {'iterations': 687, 'learning_rate': 0.06709624601489898}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:39,411]\u001b[0m Trial 95 finished with value: 0.16773069664674806 and parameters: {'iterations': 648, 'learning_rate': 0.0192251664260396}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:46,485]\u001b[0m Trial 96 finished with value: 0.16714055110399365 and parameters: {'iterations': 474, 'learning_rate': 0.09900286145801812}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:37:54,766]\u001b[0m Trial 97 finished with value: 0.16673818093424697 and parameters: {'iterations': 547, 'learning_rate': 0.04260019852256818}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:38:05,200]\u001b[0m Trial 98 finished with value: 0.17264082036679285 and parameters: {'iterations': 716, 'learning_rate': 0.14606412365651966}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n",
      "\u001b[32m[I 2023-03-04 17:38:15,866]\u001b[0m Trial 99 finished with value: 0.17556358404793282 and parameters: {'iterations': 671, 'learning_rate': 0.20574141279188107}. Best is trial 36 with value: 0.16464768049360612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 3\n",
      "Best trial: {'lambda': 1.6182442814090163, 'alpha': 7.433857773790648, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.01, 'min_child_weight': 179}\n"
     ]
    }
   ],
   "source": [
    "study_cat = optuna.create_study(direction='minimize')\n",
    "study_cat.optimize(tune_catboost, n_trials=100)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study_cat.best_trial.params\n",
    "model = CatBoostRegressor(**params)\n",
    "model.fit(df_train[feats], df_train[target], verbose=False)\n",
    "\n",
    "preds = model.predict(df_test[feats])\n",
    "dfs_pred = {}\n",
    "dfs_pred['uid'] = df_test['uid']\n",
    "dfs_pred[target] = pd.Series(preds, index=df_test.index)\n",
    "df_pred = pd.concat(dfs_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[['uid', 'is_strike']].to_csv('preds/pred_cat_optuna.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
